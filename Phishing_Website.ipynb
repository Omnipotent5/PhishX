{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: seaborn in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from seaborn) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py egg_info did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [15 lines of output]\n",
      "      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "      rather than 'sklearn' for pip commands.\n",
      "      \n",
      "      Here is how to fix this error in the main use cases:\n",
      "      - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "      - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "      - if the 'sklearn' package is used by one of your dependencies,\n",
      "        it would be great if you take some time to track which package uses\n",
      "        'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "      - as a last resort, set the environment variable\n",
      "        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "      \n",
      "      More information is available at\n",
      "      https://github.com/scikit-learn/sklearn-pypi-package\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from xgboost) (1.13.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: keras in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (3.8.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from keras) (0.14.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from keras) (0.4.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from keras) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from optree->keras) (4.11.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install numpy\n",
    "%pip install seaborn\n",
    "%pip install matplotlib\n",
    "%pip install sklearn\n",
    "%pip install xgboost\n",
    "%pip install keras\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing basic packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Label'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m data0 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFiles\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m5.urldata.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Sepratating & assigning features and target columns to X & y\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m y \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m X \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m'\u001b[39m,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      6\u001b[0m X\u001b[38;5;241m.\u001b[39mshape, y\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Label'"
     ]
    }
   ],
   "source": [
    "data0 = pd.read_csv(\"DataFiles\\\\5.urldata.csv\")\n",
    "\n",
    "# Sepratating & assigning features and target columns to X & y\n",
    "y = data['Label']\n",
    "X = data.drop('Label',axis=1)\n",
    "X.shape, y.shape\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 12)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.0098 - loss: 2.4546 - val_accuracy: 0.0340 - val_loss: 1.9602\n",
      "Epoch 2/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0406 - loss: 1.8681 - val_accuracy: 0.1295 - val_loss: 1.4199\n",
      "Epoch 3/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1684 - loss: 1.3258 - val_accuracy: 0.6895 - val_loss: 0.9346\n",
      "Epoch 4/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7903 - loss: 0.8304 - val_accuracy: 0.8500 - val_loss: 0.4504\n",
      "Epoch 5/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8376 - loss: 0.3151 - val_accuracy: 0.8500 - val_loss: -0.1652\n",
      "Epoch 6/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8427 - loss: -0.3960 - val_accuracy: 0.8500 - val_loss: -1.2818\n",
      "Epoch 7/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8401 - loss: -1.8642 - val_accuracy: 0.8500 - val_loss: -4.4777\n",
      "Epoch 8/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8355 - loss: -6.3996 - val_accuracy: 0.8500 - val_loss: -14.4200\n",
      "Epoch 9/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8480 - loss: -20.4954 - val_accuracy: 0.8500 - val_loss: -43.2047\n",
      "Epoch 10/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8399 - loss: -58.4863 - val_accuracy: 0.8500 - val_loss: -114.5702\n",
      "Epoch 11/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8433 - loss: -156.0975 - val_accuracy: 0.8500 - val_loss: -268.8486\n",
      "Epoch 12/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8385 - loss: -335.6698 - val_accuracy: 0.8500 - val_loss: -576.8229\n",
      "Epoch 13/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8368 - loss: -706.6274 - val_accuracy: 0.8500 - val_loss: -1171.8883\n",
      "Epoch 14/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8409 - loss: -1454.2234 - val_accuracy: 0.8500 - val_loss: -2213.1292\n",
      "Epoch 15/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8364 - loss: -2625.1899 - val_accuracy: 0.8500 - val_loss: -3925.7300\n",
      "Epoch 16/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8448 - loss: -4604.7388 - val_accuracy: 0.8500 - val_loss: -6606.6470\n",
      "Epoch 17/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8411 - loss: -7744.7783 - val_accuracy: 0.8500 - val_loss: -10634.2852\n",
      "Epoch 18/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8489 - loss: -12368.6094 - val_accuracy: 0.8500 - val_loss: -16467.6074\n",
      "Epoch 19/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8399 - loss: -18855.1543 - val_accuracy: 0.8500 - val_loss: -24677.5586\n",
      "Epoch 20/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8426 - loss: -28539.8906 - val_accuracy: 0.8500 - val_loss: -35990.8867\n",
      "Epoch 21/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8446 - loss: -40627.8555 - val_accuracy: 0.8500 - val_loss: -51080.6445\n",
      "Epoch 22/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8401 - loss: -57233.5859 - val_accuracy: 0.8500 - val_loss: -71329.4531\n",
      "Epoch 23/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8398 - loss: -78760.6328 - val_accuracy: 0.8500 - val_loss: -97733.3672\n",
      "Epoch 24/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8475 - loss: -109154.5000 - val_accuracy: 0.8500 - val_loss: -131683.5781\n",
      "Epoch 25/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8429 - loss: -147780.0781 - val_accuracy: 0.8500 - val_loss: -174917.2500\n",
      "Epoch 26/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8407 - loss: -188875.4375 - val_accuracy: 0.8500 - val_loss: -228609.1250\n",
      "Epoch 27/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8480 - loss: -255102.6250 - val_accuracy: 0.8500 - val_loss: -295557.6250\n",
      "Epoch 28/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8413 - loss: -324886.2812 - val_accuracy: 0.8500 - val_loss: -376756.2188\n",
      "Epoch 29/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8461 - loss: -413357.8750 - val_accuracy: 0.8500 - val_loss: -475740.1562\n",
      "Epoch 30/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8390 - loss: -519452.0625 - val_accuracy: 0.8500 - val_loss: -594215.6250\n",
      "Epoch 31/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8375 - loss: -648850.0625 - val_accuracy: 0.8500 - val_loss: -734742.8750\n",
      "Epoch 32/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8419 - loss: -812628.5000 - val_accuracy: 0.8500 - val_loss: -901354.7500\n",
      "Epoch 33/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8434 - loss: -972117.8125 - val_accuracy: 0.8500 - val_loss: -1095339.2500\n",
      "Epoch 34/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8430 - loss: -1160996.6250 - val_accuracy: 0.8500 - val_loss: -1321559.5000\n",
      "Epoch 35/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: -1445133.8750 - val_accuracy: 0.8500 - val_loss: -1585529.6250\n",
      "Epoch 36/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8412 - loss: -1726774.7500 - val_accuracy: 0.8500 - val_loss: -1888827.5000\n",
      "Epoch 37/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8403 - loss: -2003867.7500 - val_accuracy: 0.8500 - val_loss: -2235123.2500\n",
      "Epoch 38/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8436 - loss: -2382927.2500 - val_accuracy: 0.8500 - val_loss: -2635069.2500\n",
      "Epoch 39/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8444 - loss: -2867876.2500 - val_accuracy: 0.8500 - val_loss: -3088268.0000\n",
      "Epoch 40/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8437 - loss: -3313791.7500 - val_accuracy: 0.8500 - val_loss: -3596376.5000\n",
      "Epoch 41/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8463 - loss: -3926058.5000 - val_accuracy: 0.8500 - val_loss: -4173005.7500\n",
      "Epoch 42/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8407 - loss: -4477056.5000 - val_accuracy: 0.8500 - val_loss: -4815501.5000\n",
      "Epoch 43/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8408 - loss: -5207882.5000 - val_accuracy: 0.8500 - val_loss: -5531056.0000\n",
      "Epoch 44/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8420 - loss: -5829667.0000 - val_accuracy: 0.8500 - val_loss: -6336870.5000\n",
      "Epoch 45/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8471 - loss: -6707394.0000 - val_accuracy: 0.8500 - val_loss: -7228963.0000\n",
      "Epoch 46/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8460 - loss: -7810590.5000 - val_accuracy: 0.8500 - val_loss: -8220485.0000\n",
      "Epoch 47/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8410 - loss: -8677589.0000 - val_accuracy: 0.8500 - val_loss: -9313852.0000\n",
      "Epoch 48/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8450 - loss: -9991595.0000 - val_accuracy: 0.8500 - val_loss: -10511801.0000\n",
      "Epoch 49/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8456 - loss: -11179986.0000 - val_accuracy: 0.8500 - val_loss: -11840951.0000\n",
      "Epoch 50/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8485 - loss: -12515415.0000 - val_accuracy: 0.8500 - val_loss: -13280223.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# If there is a 'URL' or 'Domain' column, drop or extract features from it\n",
    "if 'URL' in X_train.columns:\n",
    "    X_train = X_train.drop('URL', axis=1)\n",
    "    X_test = X_test.drop('URL', axis=1)\n",
    "\n",
    "if 'Domain' in X_train.columns:\n",
    "    X_train = X_train.drop('Domain', axis=1)\n",
    "    X_test = X_test.drop('Domain', axis=1)\n",
    "\n",
    "# List to store model results\n",
    "results = []\n",
    "\n",
    "# Decision Tree\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train, y_train)\n",
    "y_train_tree = tree.predict(X_train)\n",
    "y_test_tree = tree.predict(X_test)\n",
    "acc_train_dt = accuracy_score(y_train, y_train_tree)\n",
    "acc_test_dt = accuracy_score(y_test, y_test_tree)\n",
    "results.append(['Decision Tree', acc_train_dt, acc_test_dt])\n",
    "\n",
    "# Random Forest\n",
    "forest = RandomForestClassifier()\n",
    "forest.fit(X_train, y_train)\n",
    "y_train_forest = forest.predict(X_train)\n",
    "y_test_forest = forest.predict(X_test)\n",
    "acc_train_rf = accuracy_score(y_train, y_train_forest)\n",
    "acc_test_rf = accuracy_score(y_test, y_test_forest)\n",
    "results.append(['Random Forest', acc_train_rf, acc_test_rf])\n",
    "\n",
    "# Multilayer Perceptrons\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100, 100, 100), alpha=0.001)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_train_mlp = mlp.predict(X_train)\n",
    "y_test_mlp = mlp.predict(X_test)\n",
    "acc_train_mlp = accuracy_score(y_train, y_train_mlp)\n",
    "acc_test_mlp = accuracy_score(y_test, y_test_mlp)\n",
    "results.append(['Multilayer Perceptrons', acc_train_mlp, acc_test_mlp])\n",
    "\n",
    "# XGBoost\n",
    "xgb = XGBClassifier(learning_rate=0.4, max_depth=7)\n",
    "xgb.fit(X_train, y_train)\n",
    "y_train_xgb = xgb.predict(X_train)\n",
    "y_test_xgb = xgb.predict(X_test)\n",
    "acc_train_xgb = accuracy_score(y_train, y_train_xgb)\n",
    "acc_test_xgb = accuracy_score(y_test, y_test_xgb)\n",
    "results.append(['XGBoost', acc_train_xgb, acc_test_xgb])\n",
    "\n",
    "# Support Vector Machine\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "y_train_svm = svm.predict(X_train)\n",
    "y_test_svm = svm.predict(X_test)\n",
    "acc_train_svm = accuracy_score(y_train, y_train_svm)\n",
    "acc_test_svm = accuracy_score(y_test, y_test_svm)\n",
    "results.append(['SVM', acc_train_svm, acc_test_svm])\n",
    "\n",
    "# Autoencoder\n",
    "input_dim = X_train.shape[1]\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoder = Dense(input_dim, activation=\"relu\",\n",
    "                activity_regularizer=regularizers.l1(10e-4))(input_layer)\n",
    "encoder = Dense(int(input_dim / 2), activation=\"relu\")(encoder)\n",
    "encoder = Dense(int(input_dim / 4), activation=\"relu\")(encoder)\n",
    "decoder = Dense(int(input_dim / 4), activation='relu')(encoder)\n",
    "decoder = Dense(int(input_dim / 2), activation='relu')(decoder)\n",
    "decoder = Dense(input_dim, activation='sigmoid')(decoder)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "autoencoder.fit(X_train, X_train, epochs=50, batch_size=256, shuffle=True, validation_data=(X_test, X_test), verbose=1)\n",
    "train_loss, acc_train_auto = autoencoder.evaluate(X_train, X_train, verbose=0)\n",
    "test_loss, acc_test_auto = autoencoder.evaluate(X_test, X_test, verbose=0)\n",
    "results.append(['AutoEncoder', acc_train_auto, acc_test_auto])\n",
    "\n",
    "# Create DataFrame and sort results\n",
    "results_df = pd.DataFrame(results, columns=['ML Model', 'Train Accuracy', 'Test Accuracy'])\n",
    "sorted_results_df = results_df.sort_values(by=['Test Accuracy', 'Train Accuracy'], ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 ML Model  Train Accuracy  Test Accuracy\n",
      "3                 XGBoost        0.865250         0.8710\n",
      "1           Random Forest        0.866125         0.8695\n",
      "0           Decision Tree        0.866125         0.8680\n",
      "2  Multilayer Perceptrons        0.864750         0.8650\n",
      "5             AutoEncoder        0.843000         0.8500\n",
      "4                     SVM        0.819000         0.8170\n"
     ]
    }
   ],
   "source": [
    "print(sorted_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save Decision Tree model\n",
    "with open('decision_tree_model.pkl', 'wb') as file:\n",
    "    pickle.dump(tree, file)\n",
    "\n",
    "# Save Random Forest model\n",
    "with open('random_forest_model.pkl', 'wb') as file:\n",
    "    pickle.dump(forest, file)\n",
    "\n",
    "# Save MLP model\n",
    "with open('mlp_model.pkl', 'wb') as file:\n",
    "    pickle.dump(mlp, file)\n",
    "\n",
    "# Save XGBoost model\n",
    "with open('xgboost_model.pkl', 'wb') as file:\n",
    "    pickle.dump(xgb, file)\n",
    "\n",
    "# Save AutoEncoder model\n",
    "with open('autoencoder_model.pkl', 'wb') as file:\n",
    "    pickle.dump(autoencoder, file)\n",
    "\n",
    "# Save SVM model\n",
    "with open('svm_model.pkl', 'wb') as file:\n",
    "    pickle.dump(svm, file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
